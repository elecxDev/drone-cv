{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad57a98",
   "metadata": {},
   "source": [
    "# Drone Vehicle Detection Analysis\n",
    "\n",
    "This notebook demonstrates the vehicle detection and counting system for aerial drone footage.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Configuration\n",
    "2. Data Loading and Exploration\n",
    "3. Model Testing\n",
    "4. Detection Analysis\n",
    "5. Tracking Analysis\n",
    "6. Results Visualization\n",
    "7. Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8188472",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from src.detection.vehicle_detector import VehicleDetector\n",
    "from src.tracking.multi_tracker import MultiTracker\n",
    "from src.utils.config_manager import ConfigManager\n",
    "from src.utils.video_processor import VideoProcessor\n",
    "from src.visualization.result_visualizer import ResultVisualizer\n",
    "from src.utils.statistics_manager import StatisticsManager\n",
    "\n",
    "# Set up matplotlib for inline plotting\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_manager = ConfigManager('../config.yaml')\n",
    "config = config_manager.get_config()\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"Model: {config['model']['type']}\")\n",
    "print(f\"Target classes: {config['detection']['target_classes']}\")\n",
    "print(f\"Confidence threshold: {config['model']['confidence_threshold']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df5eae7",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d82b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available sample data\n",
    "data_dir = Path('../data/sample')\n",
    "if data_dir.exists():\n",
    "    sample_files = list(data_dir.glob('*'))\n",
    "    print(f\"Found {len(sample_files)} sample files:\")\n",
    "    for file in sample_files:\n",
    "        print(f\"  - {file.name}\")\n",
    "else:\n",
    "    print(\"No sample data directory found. Please add sample videos to ../data/sample/\")\n",
    "    print(\"You can use any drone footage with vehicles for testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79694b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a sample video, load it here\n",
    "sample_video_path = None\n",
    "\n",
    "# Uncomment and modify the path below if you have a sample video\n",
    "# sample_video_path = '../data/sample/drone_footage.mp4'\n",
    "\n",
    "if sample_video_path and os.path.exists(sample_video_path):\n",
    "    video_processor = VideoProcessor(config)\n",
    "    video_info = video_processor.get_video_info(sample_video_path)\n",
    "    \n",
    "    print(\"Video Information:\")\n",
    "    for key, value in video_info.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"No sample video loaded. You can still run detection on individual images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660ed663",
   "metadata": {},
   "source": [
    "## 3. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac987382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize detector\n",
    "detector = VehicleDetector(config)\n",
    "print(f\"Detector initialized with device: {detector.device}\")\n",
    "print(f\"Model: {detector.model_config['type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74669c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test detection on a sample frame\n",
    "if sample_video_path and os.path.exists(sample_video_path):\n",
    "    # Read first frame from video\n",
    "    cap = cv2.VideoCapture(sample_video_path)\n",
    "    ret, test_frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if ret:\n",
    "        print(f\"Test frame shape: {test_frame.shape}\")\n",
    "        \n",
    "        # Run detection\n",
    "        detections = detector.detect(test_frame)\n",
    "        print(f\"Found {len(detections)} detections\")\n",
    "        \n",
    "        # Display detection stats\n",
    "        if detections:\n",
    "            stats = detector.get_detection_stats(detections)\n",
    "            print(\"\\nDetection Statistics:\")\n",
    "            print(f\"  Total detections: {stats['total_count']}\")\n",
    "            print(f\"  Class counts: {stats['class_counts']}\")\n",
    "            print(f\"  Average confidence: {stats['avg_confidence']:.3f}\")\n",
    "        \n",
    "        # Visualize results\n",
    "        vis_frame = detector.visualize_detections(test_frame, detections)\n",
    "        \n",
    "        # Convert BGR to RGB for matplotlib\n",
    "        vis_frame_rgb = cv2.cvtColor(vis_frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.imshow(vis_frame_rgb)\n",
    "        plt.title(f'Vehicle Detection Results - {len(detections)} vehicles detected')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Could not read frame from video\")\n",
    "else:\n",
    "    print(\"No sample video available for testing\")\n",
    "    print(\"You can test with a static image by loading it with cv2.imread()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c82aa83",
   "metadata": {},
   "source": [
    "## 4. Detection Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c12ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze detection performance across multiple frames\n",
    "if sample_video_path and os.path.exists(sample_video_path):\n",
    "    frame_count = 0\n",
    "    all_detections = []\n",
    "    detection_counts = []\n",
    "    confidences = []\n",
    "    \n",
    "    # Process first 100 frames for analysis\n",
    "    for frame in video_processor.read_video(sample_video_path):\n",
    "        if frame_count >= 100:  # Limit for notebook performance\n",
    "            break\n",
    "            \n",
    "        detections = detector.detect(frame)\n",
    "        all_detections.extend(detections)\n",
    "        detection_counts.append(len(detections))\n",
    "        \n",
    "        if detections:\n",
    "            frame_confidences = [d.confidence for d in detections]\n",
    "            confidences.extend(frame_confidences)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % 20 == 0:\n",
    "            print(f\"Processed {frame_count} frames...\")\n",
    "    \n",
    "    print(f\"\\nAnalysis complete: {frame_count} frames processed\")\n",
    "    print(f\"Total detections: {len(all_detections)}\")\n",
    "    print(f\"Average detections per frame: {np.mean(detection_counts):.2f}\")\n",
    "    print(f\"Average confidence: {np.mean(confidences):.3f}\")\n",
    "else:\n",
    "    print(\"No sample video available for multi-frame analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aead40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize detection statistics\n",
    "if 'detection_counts' in locals() and detection_counts:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Detection count over time\n",
    "    axes[0, 0].plot(detection_counts)\n",
    "    axes[0, 0].set_title('Detections per Frame')\n",
    "    axes[0, 0].set_xlabel('Frame Number')\n",
    "    axes[0, 0].set_ylabel('Number of Detections')\n",
    "    \n",
    "    # Detection count histogram\n",
    "    axes[0, 1].hist(detection_counts, bins=20, alpha=0.7)\n",
    "    axes[0, 1].set_title('Detection Count Distribution')\n",
    "    axes[0, 1].set_xlabel('Number of Detections')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Confidence distribution\n",
    "    if confidences:\n",
    "        axes[1, 0].hist(confidences, bins=30, alpha=0.7)\n",
    "        axes[1, 0].set_title('Confidence Score Distribution')\n",
    "        axes[1, 0].set_xlabel('Confidence')\n",
    "        axes[1, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Class distribution\n",
    "    if all_detections:\n",
    "        class_counts = {}\n",
    "        for detection in all_detections:\n",
    "            class_counts[detection.class_name] = class_counts.get(detection.class_name, 0) + 1\n",
    "        \n",
    "        classes = list(class_counts.keys())\n",
    "        counts = list(class_counts.values())\n",
    "        \n",
    "        axes[1, 1].pie(counts, labels=classes, autopct='%1.1f%%')\n",
    "        axes[1, 1].set_title('Vehicle Class Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd9ec95",
   "metadata": {},
   "source": [
    "## 5. Tracking Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df99c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tracker and visualizer\n",
    "tracker = MultiTracker(config)\n",
    "visualizer = ResultVisualizer(config)\n",
    "stats_manager = StatisticsManager(config)\n",
    "\n",
    "print(\"Tracker and visualizer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e5ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detection and tracking on sample frames\n",
    "if sample_video_path and os.path.exists(sample_video_path):\n",
    "    frame_count = 0\n",
    "    sample_frames = []\n",
    "    \n",
    "    # Process frames with tracking\n",
    "    for frame in video_processor.read_video(sample_video_path):\n",
    "        if frame_count >= 50:  # Limit for notebook\n",
    "            break\n",
    "        \n",
    "        # Detection\n",
    "        detections = detector.detect(frame)\n",
    "        \n",
    "        # Tracking\n",
    "        tracks = tracker.update(detections, frame)\n",
    "        \n",
    "        # Statistics\n",
    "        stats_manager.update_frame_stats(frame_count, detections, tracks)\n",
    "        \n",
    "        # Save sample frames for visualization\n",
    "        if frame_count % 10 == 0:  # Every 10th frame\n",
    "            annotated_frame = visualizer.draw_annotations(frame, detections, tracks)\n",
    "            sample_frames.append(annotated_frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % 10 == 0:\n",
    "            print(f\"Processed {frame_count} frames with tracking...\")\n",
    "    \n",
    "    print(f\"\\nTracking analysis complete: {frame_count} frames\")\n",
    "    \n",
    "    # Get tracking statistics\n",
    "    tracking_stats = tracker.get_tracking_statistics()\n",
    "    print(\"\\nTracking Statistics:\")\n",
    "    for key, value in tracking_stats.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"No sample video available for tracking analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73439c",
   "metadata": {},
   "source": [
    "## 6. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample tracked frames\n",
    "if 'sample_frames' in locals() and sample_frames:\n",
    "    n_frames = min(4, len(sample_frames))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(n_frames):\n",
    "        frame_rgb = cv2.cvtColor(sample_frames[i], cv2.COLOR_BGR2RGB)\n",
    "        axes[i].imshow(frame_rgb)\n",
    "        axes[i].set_title(f'Frame {i * 10} - Detection & Tracking')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No sample frames available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive statistics visualization\n",
    "if 'stats_manager' in locals():\n",
    "    final_stats = stats_manager.generate_final_report()\n",
    "    \n",
    "    print(\"Final Statistics Report:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if 'summary' in final_stats:\n",
    "        summary = final_stats['summary']\n",
    "        print(f\"Frames processed: {summary.get('frames_processed', 0)}\")\n",
    "        print(f\"Total detections: {summary.get('total_detections', 0)}\")\n",
    "        print(f\"Unique tracks: {summary.get('unique_tracks', 0)}\")\n",
    "        print(f\"Processing FPS: {summary.get('frames_per_second', 0):.2f}\")\n",
    "    \n",
    "    if 'density_metrics' in final_stats:\n",
    "        density = final_stats['density_metrics']\n",
    "        print(f\"\\nDensity Metrics:\")\n",
    "        print(f\"  Average density: {density.get('avg_density', 0):.2f}\")\n",
    "        print(f\"  Max density: {density.get('max_density', 0)}\")\n",
    "        print(f\"  Density trend: {density.get('density_trend', 'unknown')}\")\n",
    "    \n",
    "    if 'class_distribution' in final_stats:\n",
    "        class_dist = final_stats['class_distribution']\n",
    "        print(f\"\\nClass Distribution:\")\n",
    "        if 'detections' in class_dist:\n",
    "            for class_name, count in class_dist['detections'].items():\n",
    "                print(f\"  {class_name}: {count}\")\n",
    "else:\n",
    "    print(\"No statistics available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc381f23",
   "metadata": {},
   "source": [
    "## 7. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18352b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance metrics\n",
    "if 'final_stats' in locals() and 'performance_metrics' in final_stats:\n",
    "    perf = final_stats['performance_metrics']\n",
    "    \n",
    "    print(\"Performance Analysis:\")\n",
    "    print(\"=\" * 30)\n",
    "    print(f\"Average processing time: {perf.get('avg_processing_time', 0):.3f} seconds\")\n",
    "    print(f\"Estimated FPS: {perf.get('fps_estimate', 0):.2f}\")\n",
    "    print(f\"Max processing time: {perf.get('max_processing_time', 0):.3f} seconds\")\n",
    "    print(f\"Min processing time: {perf.get('min_processing_time', 0):.3f} seconds\")\n",
    "    \n",
    "    # Create performance visualization\n",
    "    if 'stats_manager' in locals():\n",
    "        processing_times = stats_manager.processing_times\n",
    "        \n",
    "        if processing_times:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            \n",
    "            # Processing time over frames\n",
    "            axes[0].plot(processing_times)\n",
    "            axes[0].set_title('Processing Time per Frame')\n",
    "            axes[0].set_xlabel('Frame Number')\n",
    "            axes[0].set_ylabel('Processing Time (seconds)')\n",
    "            \n",
    "            # Processing time histogram\n",
    "            axes[1].hist(processing_times, bins=20, alpha=0.7)\n",
    "            axes[1].set_title('Processing Time Distribution')\n",
    "            axes[1].set_xlabel('Processing Time (seconds)')\n",
    "            axes[1].set_ylabel('Frequency')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"No performance metrics available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ea941e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the complete pipeline for drone vehicle detection and counting:\n",
    "\n",
    "1. **Detection**: Using YOLO models to identify vehicles in aerial footage\n",
    "2. **Tracking**: Maintaining object identities across frames\n",
    "3. **Analysis**: Computing traffic density and flow metrics\n",
    "4. **Visualization**: Creating annotated outputs and statistical plots\n",
    "\n",
    "### Next Steps:\n",
    "- Add your own drone footage to `../data/sample/`\n",
    "- Experiment with different model configurations\n",
    "- Analyze longer video sequences\n",
    "- Implement custom traffic analysis features\n",
    "\n",
    "### Key Features:\n",
    "- Real-time processing capabilities\n",
    "- Multiple vehicle class detection\n",
    "- Robust multi-object tracking\n",
    "- Comprehensive statistics and visualization\n",
    "- Configurable parameters for different scenarios"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
